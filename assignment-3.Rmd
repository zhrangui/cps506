---
title: 'CIND 123 - Data Analytics: Basic Methods'
author: Rui Zhang
output:
  pdf_document: default
  word_document: default
  html_document: default
---
<center> <h1> Assignment 3 (10%) </h1> </center>
<center>  <h3> Rui Zhang </h2> </center>
<center> <h3> DHA 500736315 </h2> </center>
---
## Instructions 

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. Review this website for more details on using R Markdown <http://rmarkdown.rstudio.com>.

Use RStudio for this assignment. Complete the assignment by inserting your R code wherever you see the string "#INSERT YOUR ANSWER HERE".

When you click the **Knit** button, a document (PDF, Word, or HTML format) will be generated that includes both the assignment content as well as the output of any embedded R code chunks.

Submit **both**  the rmd and generated output files. Failing to submit both files will be subject to mark deduction.

## Sample Question and Solution

Use `seq()` to create the vector $(2,4,6,\ldots,20)$.

```{r}
#Insert your code here.
seq(2,20,by = 2)
```


## Question 1

Use the following commands to install the `airquality` dataset and load the `datasets` package into your session.
```{r}
#install.packages("datasets")
library(datasets) 
data(airquality)
str(airquality)
```


a) Use a histogram to assess the normality of the `Ozone` variable, then explain why it does not appear normally distributed.
```{r}
hist(airquality$Ozone, xlim=c(0,200), ylim=c(0, 40))
#Ozone is not symmetric as normal distribution is.
#It is heavily skewed to right
```

b) Create a set of boxplots that shows the distribution of `Ozone` in each month. 
Use different colors for each month.
```{r}
library(dplyr)
dist <- group_by(airquality[!is.na(airquality$Ozone),], Month) %>%
group_split()
box <- sapply(dist, function(x){x$Ozone})
nms <- unique(airquality$Month)
boxplot(box, names=nms, col = c("orange","red", "yellow","blue","green"), xlab="Month", ylab="Ozone")
```



##Question 2

Use the following commands to install the `marketing` dataset and load the `datarium` package into your session.
```{r}
#install.packages("datarium")
library(datarium)
data("marketing", package = "datarium")
str(marketing)
```

a)  Find the covariance between the `Sales` and the advertising budget of `newspaper`. Comment on the output, in terms of the strength and direction of the relationship.
```{r}
cov(marketing$sales, marketing$newspaper)
cor(marketing$sales, marketing$newspaper)
# Sales and newspaper are positive correlated, since correlation coefficient is 0.228, they have weak correlation
```

b) Plot the `Sales` as a function of the `Youtube` variable using a scatterplot, then graph the least-square line on the same plot. 
Hint: You may use the `ggplot()` function from `ggplot2` package. 

```{r}
#install.packages("ggplot2")
library(ggplot2)
model<-lm(sales~youtube, marketing)
ggplot(marketing, aes(youtube, sales))+
  geom_point()+
  stat_smooth(method = "lm", col = "red")
```

c) Use the regression line to predict the `Sales` amount when `newspaper` budget is `$136.80K`. Comment on the difference between the output and the expected value. 
```{r}
sn<-lm(sales~newspaper, marketing)
summary(sn)
df.newspaper<-data.frame(newspaper<-c(136.80))
output<-marketing[which(marketing$newspaper>136.5),]$sales
prd<-predict(sn, df.newspaper)
diff<-prd-output
output
prd
diff
diff/output
# There is a difference of sales 7.303704 and 0.4869136 relative error between the output and the expected value. newspaper doesn't give good estimation of sales. The t value 3.30 and p value 0.00115 of newspaper also explains that sales have little linear correlation with newspaper
```

d) Use `newspaper` and `facebook` variables to build a linear regression model to predict `sales`. Display a summary of your model indicating Residuals, Coefficients, ..., etc. What conclusion can you draw from this summary?
```{r}
snf<-lm(sales~newspaper+facebook, marketing)
summary(snf)
# R-squared=0.3327, this linear regress only explains 33.27% change by independent newspaper and facebook
# Residuals still show that a big gap can't drawn from these two independent varibles.
# t and p value of newspaper is so big, they reject newspaper is good varible to estimate sales
# but small t and p value of facebook draws a conclusion that it has majour influence on sales and contributes the main change of sales
```

e) Use the regression line to predict the `Sales` amount when `newspaper` budget is `$136.80K` and `facebook` is `$43.92K`.
```{r}
snf<-lm(sales~newspaper+facebook, marketing)
df.independents<-data.frame(newspaper<-c(136.80), facebook<-c(43.92))
prd<-predict(snf, df.independents)
prd
```

f) What is the difference between the output in (e) and the output in (c)
```{r}
output<-marketing[which(marketing$newspaper>136.7&marketing$facebook==43.92),]$sales
output
22.3037-20.67767 
#(e) with newspaper and facebook variables has more precise closer to observed sale, 15, than (c)'s. The different 1.62603 between (e) and (c) is contributed by facebook variable to predict the observed one more accurately
```

g) Display the correlation matrix of the variables: `youtube`, `facebook`, `newspaper` and `sales`. What conclusion can you draw?
```{r}
syfn<-c("sales", "youtube", "facebook", "newspaper")
cor(marketing[syfn], method="pearson")
# sales is biggest affected by youtube, they have strong positive linear correlation
# youtube and facebook have weakest positive linear correlation arround 0.05480866
```

h) In your opinion, which statistical test should be used to discuss the relationship between `youtube` and `sales`?
Hint:  Review the differnce between Pearson and Spearman tests.
```{r}
cor(marketing$sales, marketing$youtube, method="pearson")
cor(marketing$sales, marketing$youtube, method="spearman")
# Pearson correlation should be used to discuss the relation between youtube and sales, because the data from youtube and sales are continuous numeric and linear data.
# spearman correlation is better used to ranking, nonlinear data 
```


##Question 3

Install the `carData` dataset on your computer using the command `install.packages("carData")`. Then load the `CanPop: Canadian Population Data` into your session using the following command.  The CanPop` has 16 rows and 2 columns and represent the decennial time-series of Canadian population between 1851 and 2001.
```{r}
#install.packages("carData")
library("carData")
data("CanPop", package = "carData")
str(CanPop)
```

a) Which of the two variables is the independent variable and which is the dependent variable? Explain your choice.
```{r}
# year is independent, it doesn't change by any external factor.
# population is dependent, the number changes with year, and it is affected by many factors like year.
```

b) Assuming that year and population are linearly related, give the equation and the graph of the least-squares regression line.
Hint: use lm() function.
```{r}
model.py<-lm(population~year, CanPop)
summary(model.py)
# population = -337.09856 + 0.18134*year
plot(CanPop$year, CanPop$population, las=1)
abline(model.py)

```

c) Explain the meaning of the slope and y-intercept for the least-squares regression line in (b).
```{r}
#slope means that the population inceases 0.18134 when year increases one, population increasing rate is 0.18134 by year
#intercept means the population is -337.09856 when year equals 0. it is not correct, population can't be zero, that mean the prediction may not right if the predictiing data range is beyond sample data range
```

d) In year 2020, what would you predict the population's size to be.  Does the value of the predicted size matches your expectations? Explain.
```{r}
model.py<-lm(population~year, CanPop)
predict
# the prediction is 29.19844, which is lower than 30.007 in 2001. It doesn't match my expectation,
# because the calculation is extrapolation estimation, the value of independent variable is far from sample data. That is why the regression line fails, the range of independent variable doesn't cover the required value which is applied to prediction future value

```